{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <h1>AI Agents : Tool Calling & Langgraph with Amazon Bedrock</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Tool Calling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Create Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting seval\n",
      "  Downloading seval-1.1.0-py3-none-any.whl.metadata (391 bytes)\n",
      "Requirement already satisfied: pytest in c:\\users\\97254\\appdata\\roaming\\python\\python312\\site-packages (from seval) (8.4.2)\n",
      "Requirement already satisfied: colorama>=0.4 in c:\\users\\97254\\appdata\\roaming\\python\\python312\\site-packages (from pytest->seval) (0.4.6)\n",
      "Requirement already satisfied: iniconfig>=1 in c:\\users\\97254\\appdata\\roaming\\python\\python312\\site-packages (from pytest->seval) (2.1.0)\n",
      "Requirement already satisfied: packaging>=20 in c:\\users\\97254\\appdata\\roaming\\python\\python312\\site-packages (from pytest->seval) (24.1)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in c:\\users\\97254\\appdata\\roaming\\python\\python312\\site-packages (from pytest->seval) (1.6.0)\n",
      "Requirement already satisfied: pygments>=2.7.2 in c:\\users\\97254\\appdata\\roaming\\python\\python312\\site-packages (from pytest->seval) (2.18.0)\n",
      "Downloading seval-1.1.0-py3-none-any.whl (4.5 kB)\n",
      "Installing collected packages: seval\n",
      "Successfully installed seval-1.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install seval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from seval import safe_eval\n",
    "\n",
    "@tool\n",
    "def calculator(numeric_formula: str) -> float:\n",
    "    \"\"\"Evaluate a complex numeric formula (containing only floats and the operators +, -, *, /, **, and parentheses) and return the result.\"\"\"\n",
    "    return safe_eval(numeric_formula)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Bind Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "with open('secrets.yml', 'r') as file:\n",
    "    credentials = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_aws import ChatBedrock\n",
    "\n",
    "raw_llm = ChatBedrock(\n",
    "    model_id=\"us.anthropic.claude-3-5-sonnet-20240620-v1:0\",\n",
    "    region_name=\"us-east-1\",\n",
    "    aws_access_key_id=credentials[\"bedrock\"][\"access_key\"],\n",
    "    aws_secret_access_key=credentials[\"bedrock\"][\"secret_key\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_llm = raw_llm.bind_tools([calculator])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Invoke Tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we want to evaluate : $e^\\pi - \\pi^e$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is the result of e to the pi minus pi to the e ? Reply directly with the answer.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = raw_llm.invoke(query)\n",
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = tool_llm.invoke(query)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_calls = result.tool_calls\n",
    "tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculator.invoke(tool_calls[0][\"args\"][\"numeric_formula\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Simple AI Agent with Langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Desired Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Step 1 : Invoke the LLM on initial message.\n",
    "\n",
    "* Step 2 : If the LLM answers directly, then END. If the LLM outputs a tool call, invoke the tool.\n",
    "\n",
    "* Step 3 : Add tool output to messages and Invoke LLM. Go back to Step 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Graph Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2.1 Graph & State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2.2 Graph Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLMNode:\n",
    "    def __init__(self, llm):\n",
    "        self.llm = llm\n",
    "\n",
    "    def __call__(self, state: State):\n",
    "        return {\"messages\": [self.llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "llm_node = LLMNode(tool_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "tool_node = ToolNode([calculator])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder.add_node(\"llm\", llm_node)\n",
    "graph_builder.add_node(\"tools\", tool_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2.3 Graph Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "graph_builder.add_edge(START, \"llm\") # Step 1\n",
    "\n",
    "graph_builder.add_conditional_edges(\"llm\", tools_condition) # Step 2\n",
    "\n",
    "graph_builder.add_edge(\"tools\", \"llm\") # Step 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 AI Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(agent.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": query}]},\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
